{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/saraiva/anaconda3/lib/python3.6/site-packages (3.3)\n",
      "Requirement already satisfied: six in /home/saraiva/anaconda3/lib/python3.6/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = countvec.fit_transform(['varias','batataws,babata'])\n",
    "a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tokenize(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = nltk.word_tokenize(sentence)\n",
    "    return sentence\n",
    "\n",
    "def Stemming(sentence):\n",
    "    stemmer = RSLPStemmer()\n",
    "    phrase = []\n",
    "    for word in sentence:\n",
    "        phrase.append(stemmer.stem(word.lower()))\n",
    "    return phrase\n",
    "\n",
    "def RemoveStopWords(sentence):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    phrase = []\n",
    "    for word in sentence:\n",
    "        if word not in stopwords:\n",
    "            phrase.append(word)\n",
    "    return phrase\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize('Eu gosto muito de comer batatas recheadas com queijo e peito de peru',language = 'portuguese')\n",
    "\n",
    "stemmin = RSLPStemmer()\n",
    "stemmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-b18ad7b43f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstemmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eu gosto muito de comer batatas recheadas com queijo e peito de peru'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'portuguese'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/rslp.py\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# the word ends in 's'? apply rule for plural reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "stemmin.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu\n",
      "gost\n",
      "muit\n",
      "de\n",
      "com\n",
      "batat\n",
      "reche\n",
      "com\n",
      "queij\n",
      "e\n",
      "peit\n",
      "de\n",
      "peru\n",
      "o\n",
      "camill\n",
      "é\n",
      "muit\n",
      "viad\n",
      "ele\n",
      "ador\n",
      "and\n",
      "de\n",
      "motoc\n"
     ]
    }
   ],
   "source": [
    "corpus = ['Eu gosto muito de comer batatas recheadas com queijo e peito de peru',\n",
    "          'o Camillo é muito viadinho',\n",
    "          'ele adora andar de motoca']\n",
    "\n",
    "\n",
    "\n",
    "for sentence in corpus:\n",
    "    for token in sentence.split():\n",
    "        print(stemmin.stem(token))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_comments = ['Eu amo batata','Eu odeio jogar dotinha','Curto mesmo é chapar','Odeio dota','Amo dota'\n",
    "               ,'Vai se foder lolzinho','Eu amo Itaú']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['the car is driven on the road','the truck is driven on the highway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(smooth_idf=False)\n",
    "result = vectorizer.fit_transform(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t0.5604749267301206\n",
      "  (0, 0)\t0.47448327098382276\n",
      "  (0, 3)\t0.2802374633650603\n",
      "  (0, 1)\t0.2802374633650603\n",
      "  (0, 4)\t0.2802374633650603\n",
      "  (0, 5)\t0.47448327098382276\n",
      "  (1, 6)\t0.5604749267301206\n",
      "  (1, 3)\t0.2802374633650603\n",
      "  (1, 1)\t0.2802374633650603\n",
      "  (1, 4)\t0.2802374633650603\n",
      "  (1, 7)\t0.47448327098382276\n",
      "  (1, 2)\t0.47448327098382276\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.474483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driven</th>\n",
       "      <td>0.280237</td>\n",
       "      <td>0.280237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.280237</td>\n",
       "      <td>0.280237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>0.280237</td>\n",
       "      <td>0.280237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>0.474483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.560475</td>\n",
       "      <td>0.560475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truck</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1\n",
       "car      0.474483  0.000000\n",
       "driven   0.280237  0.280237\n",
       "highway  0.000000  0.474483\n",
       "is       0.280237  0.280237\n",
       "on       0.280237  0.280237\n",
       "road     0.474483  0.000000\n",
       "the      0.560475  0.560475\n",
       "truck    0.000000  0.474483"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(result.toarray(),\n",
    "            columns = vectorizer.get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30102999566398114"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t0.5604749267301206\n",
      "  (0, 0)\t0.47448327098382276\n",
      "  (0, 3)\t0.2802374633650603\n",
      "  (0, 1)\t0.2802374633650603\n",
      "  (0, 4)\t0.2802374633650603\n",
      "  (0, 5)\t0.47448327098382276\n",
      "  (1, 6)\t0.5604749267301206\n",
      "  (1, 3)\t0.2802374633650603\n",
      "  (1, 1)\t0.2802374633650603\n",
      "  (1, 4)\t0.2802374633650603\n",
      "  (1, 7)\t0.47448327098382276\n",
      "  (1, 2)\t0.47448327098382276\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = {}\n",
    "words.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "car\n",
      "is\n",
      "driven\n",
      "on\n",
      "the\n",
      "road\n",
      "the\n",
      "truck\n",
      "is\n",
      "driven\n",
      "on\n",
      "the\n",
      "highway\n"
     ]
    }
   ],
   "source": [
    "#Calculando tf\n",
    "words = {}\n",
    "for s in sentences:\n",
    "    phrase_list = s.split()\n",
    "    for single_word in phrase_list:\n",
    "        if(words[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
